/*
	AI factory | TOGETHER.AI
	USES OPENAI LIBRARY
	Default model: meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo
	https://docs.together.ai/

	Direct https request:

	curl https://api.together.xyz/v1/chat/completions \
		-H "Content-Type: application/json" \
		-H "Authorization: Bearer xai-uDclYK1cili0u3MbcX7ulgzIZjCYzbwWzjpTKHSG4ppKlzVqLhicTy05Eafgwl2xhiBYFlnJzF7wJMVH" \
		-d '{
		"messages": [
			{
			"role": "system",
			"content": "You are a test assistant."
			},
			{
			"role": "user",
			"content": "Testing. Just say hi and hello world and nothing else."
			}
		],
		"model": "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo",
		"stream": false,
		"temperature": 0
}'
*/

var entityos = require('entityos')
var _ = require('lodash')
var moment = require('moment');

module.exports = 
{
	VERSION: '1.0.0',

	init: function (param)
	{
		entityos.add(
		{
			name: 'ai-gen-util-chat',
			code: function (param)
			{
				const settings = entityos.get({scope: '_settings'});
                let aiSettings = _.get(param, 'settings');

				let keyPath = _.get(aiSettings, 'service.keypath');

				let apiKey = _.get(settings, keyPath);
				
				const apiBaseURL = 'https://'
					+ _.get(aiSettings, 'service.host.name', 'api.x.ai')
					+ _.get(aiSettings, 'service.host.basePath', '/v1');

                const OpenAI = require("openai");

                const xai = new OpenAI(
                {
                    apiKey: apiKey,
					baseURL: apiBaseURL
                });

				const maxTokensDefault = _.get(settings, 'ai.defaults.maxtokens', 1000);
				const temperatureDefault = _.get(settings, 'ai.defaults.temperature', 0.7);

				const maxTokens = _.get(param, 'maxTokens', maxTokensDefault);
				const temperature = _.get(param, 'temperature', temperatureDefault);

				let messages = _.get(param, 'messages', {});

				if (messages.system == undefined)
				{
					messages.system = _.get(aiSettings, 'ai.defaults.messages.system');
				}

				if (messages.user == undefined)
				{
					entityos.invoke('util-end', {error: 'No user messages!'});
				}
				else
				{
					let chatMessages =
					[
						{ role: 'system', content: messages.system }
					];

					const attachments = _.get(param, 'attachments');
					
					if (attachments != undefined)
					{
						_.each(attachments, function (attachment)
						{
							if (attachment.base64 != undefined)
							{
								chatMessages.push(
								{
									role: 'user',
									content:
									[
										{ type: 'text', text: messages.user},
										{
											type: 'image_url',
											image_url:
											{
												url: 'data:image/png;base64,' + attachment.base64
											}
										}
									]
								});
							}

							if (attachment.url != undefined)
							{
								chatMessages.push(
								{
									role: 'user',
									content:
									[
										{ type: 'text', text: messages.user},
										{
											type: 'image_url',
											image_url:
											{
												url: attachment.url
											}
										}
									]
								});
							}
						});
					}

					if (_.find(chatMessages, function (chatMessage) {return chatMessage.role == 'user'}) == undefined)
					{
						chatMessages.push({role: 'user', content: messages.user})
					}

					console.log(aiSettings.model.name)

					xai.chat.completions.create({
						model: aiSettings.model.name,
						messages: chatMessages,
						max_tokens: maxTokens,
						temperature: temperature
					})
					.then(function (completion)
					{
						_.set(param, 'messages.response', completion.choices[0]?.message?.content);

						if (_.get(param, 'onComplete') != undefined)
						{
							entityos._util.onComplete(param);
						}
						else
						{
							entityos.invoke('util-end', param);
						}
					})
					.catch(function (responseError)
					{
						//console.log(responseError)
						_.set(param, 'messages.response',  '!!: ' + _.get(responseError, 'error'));

						if (_.get(param, 'onComplete') != undefined)
						{
							entityos._util.onComplete(param);
						}
						else
						{
							entityos.invoke('util-end', param);
						}
					});
				}
			}
		});

		entityos.add(
		{
			name: 'ai-gen-util-service-models',
			code: function (param)
			{
				const settings = entityos.get({scope: '_settings'});
                let aiSettings = _.get(param, 'settings');
				
				if (aiSettings == undefined)
				{
					aiSettings = entityos.invoke('ai-gen-util-get-settings');
				}

				//console.log(aiSettings)

				let keyPath = _.get(aiSettings, 'service.keypath');
				let apiKey = _.get(settings, keyPath);

                const OpenAI = require("openai");

                const openai = new OpenAI(
                {
                    apiKey: apiKey
                });

				openai.models.list()
				.then(function(response)
				{
					let models = response.data;
					_.each(models, function (model)
					{
						model.isChat = (model.id.startsWith("gpt-") || model.id.includes("chat"))
					});

					//console.log(models);

					_.set(param, 'models', models);
					_.set(param, 'modelsChat', _.filter(models, function (model) {return model.isChat} ))
					_.set(param, 'modelsChatSimple', _.filter(models, function (model) {return (model.isChat && _.split(model.id, '-').length <= 3)}))

					if (_.get(param, 'onComplete') != undefined)
					{
						entityos._util.onComplete(param)
					}
					else
					{
						entityos.invoke('util-end', param);
					}
				})
				.catch(function(err)
				{
					console.error("Error listing models:", err);
				});
			}
		});
	}
}